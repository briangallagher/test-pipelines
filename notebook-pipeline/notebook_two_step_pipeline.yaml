# PIPELINE DEFINITION
# Name: notebook-two-step-pipeline
# Description: Use notebook components to generate and process a dataset.
# Inputs:
#    min_length: int [Default: 0.0]
#    num_rows: int [Default: 5.0]
#    prefix: str [Default: 'item']
#    seed: int [Default: 42.0]
components:
  comp-nb-generate-data:
    executorLabel: exec-nb-generate-data
    inputDefinitions:
      parameters:
        num_rows:
          defaultValue: 5.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        prefix:
          defaultValue: item
          isOptional: true
          parameterType: STRING
        seed:
          defaultValue: 42.0
          isOptional: true
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        generated_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-nb-process-data:
    executorLabel: exec-nb-process-data
    inputDefinitions:
      artifacts:
        input_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        min_length:
          defaultValue: 0.0
          isOptional: true
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        output_metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        output_results:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-nb-generate-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - nb_generate_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'datasets' 'nbclient'\
          \ 'nbformat' 'ipykernel'  &&  python3 -m pip install --quiet --no-warn-script-location\
          \ 'kfp==2.14.6' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"\
          3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\n__KFP_EMBEDDED_ARCHIVE_B64 = 'H4sIAH05DmkC/+1WzW+bSBT3OX/FiF5ASomNTZJacrWH1WpvWym9xREazANPDTNoGFpbyP/7vgeYCsebVSOlh3Z+hwHem/f9Yfs3/s0fn/j+b+AJ6MmbYNrhv57T6Xzx/Z3os2kwCyZsP/kJqCvDNZqf/J4I7llhRAGr2d1tEM4/3N8v/PniPribh1cTi18eGUjQ3ECUcMN9UR5k/Cbzf7voZvzuNuxmPRhmfh4Es8ksnOEamC/CEOmzMLybT9j0Z85/rAWXGc9znm0vLUK8lqa/Xv2bK8acDeR55SzZI34w1rRnT47MoQRkORuVgHN9YsEeNrURSkYbVUuDF2Sd5wO7AMOpoZDeHAeqqk1Zm9bQ00CsVK03MBhvae/YJ645KgFdMSG/wMZAwuIDS6rc17WMpDIQK7Vby8ElFJN1EWn1rWIrluUq5nnlen4Gxl0PrLVzzUJvLFZqSMX+glDHIJG1IwwUa+dMsgJ0a4UeGvdcllgkuQi8M6Fz4yS9dh5lvBzN4hN7wMY0QmZsiNbxLgmnF6XbDFbs/Ud2in3VnN6O16yLbdV0TySQw6uGzuMzO+MvUZRKG6aqi2TNZaKKMSvVqmDkVgUGC9pd/LP7fsnSO/ZPSU3G8yWrK2h9ZEaxgu+A9fEimyXUKYWQojJiM1bRueOTpEvHi5H1zfP4dOa+0kxglSm2DFzK+SmTnrcc36XDwN6gGqzLKb3vG4FZfX6TVPi8LEEmboNNhi2zbNtJeNR0pIgo9KTvHGRmtkTBN5eo3tF7OYEP2zpNcxinCLfcgcWY/YRh9tqsuhRkAoXyLuevU+O2Mb9ksa8yht/X16fiRzna/X/hbkFEidAov3ZuTFHe7NIyknHU747zJKrKp2ZAicr9Ln3NYI8GI7VbfdY1nNmkqUr5xkQlN1s0hDrozf+ihBwpWZ+i+aHBe+BfaWhPifgm0EhD9WrDP7Y1pyZuRn48H7pegV/xrxAZhS5VO3ck89rF8he1wRaLPl4svexT+zzi2S7p0S5vWU6OY1DzDCIhUzWQaQHjzqbfivJgtqpXSIranwBHxthjBacfi8WIEGFfKo3k4Opo/3RaWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWLwe/wJ7ZT6qACgAAA=='\n\
          __KFP_NOTEBOOK_REL_PATH = 'generate_data.ipynb'\n\nimport base64 as __kfp_b64\n\
          import gzip as __kfp_gzip\nimport io as __kfp_io\nimport os as __kfp_os\n\
          import sys as __kfp_sys\nimport tarfile as __kfp_tarfile\nimport tempfile\
          \ as __kfp_tempfile\nfrom nbclient import NotebookClient\n\n# Extract embedded\
          \ archive at import time to ensure sys.path and globals are set\nprint('[KFP]\
          \ Extracting embedded notebook archive...', flush=True)\n__kfp_tmpdir =\
          \ __kfp_tempfile.TemporaryDirectory()\n__KFP_EMBEDDED_ASSET_DIR = __kfp_tmpdir.name\n\
          try:\n    __kfp_bytes = __kfp_b64.b64decode(__KFP_EMBEDDED_ARCHIVE_B64.encode('ascii'))\n\
          \    with __kfp_tarfile.open(fileobj=__kfp_io.BytesIO(__kfp_bytes), mode='r:gz')\
          \ as __kfp_tar:\n        __kfp_tar.extractall(path=__KFP_EMBEDDED_ASSET_DIR)\n\
          \    print(f'[KFP] Notebook archive extracted to: {__KFP_EMBEDDED_ASSET_DIR}',\
          \ flush=True)\nexcept Exception as __kfp_e:\n    raise RuntimeError(f'Failed\
          \ to extract embedded notebook archive: {__kfp_e}')\n\n# Always prepend\
          \ the extracted directory to sys.path for import resolution\nif __KFP_EMBEDDED_ASSET_DIR\
          \ not in __kfp_sys.path:\n    __kfp_sys.path.insert(0, __KFP_EMBEDDED_ASSET_DIR)\n\
          \    print(f'[KFP] Added notebook archive directory to Python path', flush=True)\n\
          \n# Optional convenience for generic embedded file variable name\n__KFP_EMBEDDED_ASSET_FILE\
          \ = __kfp_os.path.join(__KFP_EMBEDDED_ASSET_DIR, __KFP_NOTEBOOK_REL_PATH)\n\
          \n\nclass KFPStreamingNotebookClient(NotebookClient):\n    # Streams outputs\
          \ in real-time by emitting outputs during message processing.\n    def process_message(self,\
          \ msg, cell, cell_index):\n        # Call the parent implementation to handle\
          \ the message normally\n        output = super().process_message(msg, cell,\
          \ cell_index)\n\n        # If an output was created, stream it immediately\n\
          \        if output is not None:\n            _kfp_stream_single_output(output,\
          \ cell_index)\n\n        return output\n\ndef __kfp_write_parameters_cell(nb,\
          \ params):\n    \"\"\"Inject parameters following Papermill semantics.\n\
          \n    - If a cell tagged with 'parameters' exists, insert an overriding\n\
          \      'injected-parameters' cell immediately after it.\n    - Otherwise,\
          \ insert the 'injected-parameters' cell at the top.\n    \"\"\"\n    import\
          \ json\n\n    import nbformat\n\n    if not params:\n        return\n\n\
          \    # Build the injected parameters cell\n    assignments = []\n    for\
          \ key, value in params.items():\n        serialized = json.dumps(value)\n\
          \        assignments.append(key + ' = json.loads(' + repr(serialized) +\
          \ ')')\n    source = 'import json\\n' + '\\n'.join(assignments) + '\\n'\n\
          \    cell = nbformat.v4.new_code_cell(source=source)\n    cell.metadata.setdefault('tags',\
          \ [])\n    if 'injected-parameters' not in cell.metadata['tags']:\n    \
          \    cell.metadata['tags'].append('injected-parameters')\n\n    # Locate\
          \ the first 'parameters' tagged cell\n    insert_idx = 0\n    for idx, existing\
          \ in enumerate(nb.get('cells', [])):\n        if existing.get('cell_type')\
          \ != 'code':\n            continue\n        tags = existing.get('metadata',\
          \ {}).get('tags', []) or []\n        if 'parameters' in tags:\n        \
          \    insert_idx = idx + 1\n            break\n\n    nb.cells.insert(insert_idx,\
          \ cell)\n\ndef _kfp_stream_single_output(output, cell_idx):\n    \"\"\"\
          Stream a single notebook output immediately during execution.\n\n    Prints\
          \ stdout/stderr and text/plain display outputs to the console\n    so users\
          \ see cell output as it happens (no need to wait until the\n    notebook\
          \ finishes).\n    \"\"\"\n    import sys\n    output_type = output.get('output_type')\n\
          \n    if output_type == 'stream':\n        text = output.get('text', '')\n\
          \        if text:\n            try:\n                print(f'[nb cell {cell_idx}\
          \ stream] ', end='', flush=False)\n            except Exception:\n     \
          \           pass\n            print(text, end='' if text.endswith('\\n')\
          \ else '\\n', flush=True)\n    elif output_type == 'error':\n        for\
          \ line in output.get('traceback', []):\n            print(line, file=sys.stderr,\
          \ flush=True)\n    else:\n        # Handle display_data and execute_result\n\
          \        data = output.get('data', {})\n        if 'text/plain' in data:\n\
          \            print(data['text/plain'], flush=True)\n        elif 'application/json'\
          \ in data:\n            try:\n                import json as __kfp_json\n\
          \                parsed = data['application/json']\n                # Some\
          \ kernels send JSON as string; try to parse if needed\n                if\
          \ isinstance(parsed, str):\n                    try:\n                 \
          \       parsed = __kfp_json.loads(parsed)\n                    except Exception:\n\
          \                        pass\n                print(\n                \
          \    __kfp_json.dumps(parsed, indent=2, ensure_ascii=False),\n         \
          \           flush=True)\n            except Exception:\n               \
          \ # Fallback to raw\n                print(str(data.get('application/json')),\
          \ flush=True)\n        elif 'text/markdown' in data:\n            # Print\
          \ markdown as-is; frontends may render, logs will show raw markdown\n  \
          \          print(data['text/markdown'], flush=True)\n\ndef kfp_run_notebook(**kwargs):\n\
          \    \"\"\"Execute the embedded notebook with injected parameters.\n\n \
          \   Parameters provided via kwargs are injected into the notebook\n    following\
          \ Papermill semantics (after a parameters cell if present,\n    otherwise\
          \ at top). Execution uses a Python kernel; nbclient and\n    ipykernel must\
          \ be available at runtime (installed via\n    packages_to_install for notebook\
          \ components).\n    \"\"\"\n    import os\n    import subprocess\n    import\
          \ sys\n\n    from nbclient import NotebookClient\n    import nbformat\n\n\
          \    # Ensure a usable 'python3' kernel is present; install kernelspec if\
          \ missing\n    print('[KFP Notebook] Checking for Python kernel...', flush=True)\n\
          \    try:\n        from jupyter_client.kernelspec import KernelSpecManager\
          \  # type: ignore\n        ksm = KernelSpecManager()\n        have_py3 =\
          \ 'python3' in ksm.find_kernel_specs()\n        if not have_py3:\n     \
          \       print(\n                '[KFP Notebook] Python3 kernel not found,\
          \ installing...',\n                flush=True)\n            try:\n     \
          \           subprocess.run([\n                    sys.executable, '-m',\
          \ 'ipykernel', 'install', '--user',\n                    '--name', 'python3',\
          \ '--display-name', 'Python 3'\n                ],\n                   \
          \            check=True,\n                               stdout=subprocess.DEVNULL,\n\
          \                               stderr=subprocess.DEVNULL)\n           \
          \     print(\n                    '[KFP Notebook] Python3 kernel installed\
          \ successfully',\n                    flush=True)\n            except subprocess.CalledProcessError\
          \ as e:\n                raise RuntimeError(\n                    \"Failed\
          \ to install 'python3' kernelspec for ipykernel. \"\n                  \
          \  \"Ensure ipykernel is available in the environment or include it via\
          \ packages_to_install. \"\n                    f\"Error: {e}\") from e\n\
          \        else:\n            print('[KFP Notebook] Python3 kernel found',\
          \ flush=True)\n    except ImportError as e:\n        raise RuntimeError(\n\
          \            \"jupyter_client is not available. Ensure it's installed in\
          \ the environment or include it via packages_to_install. \"\n          \
          \  f\"Error: {e}\") from e\n\n    nb_path = os.path.join(__KFP_EMBEDDED_ASSET_DIR,\
          \ __KFP_NOTEBOOK_REL_PATH)\n\n    try:\n        nb = nbformat.read(nb_path,\
          \ as_version=4)\n    except Exception as e:\n        raise RuntimeError(\n\
          \            f'Failed to read notebook {nb_path}. Ensure it is a valid Jupyter\
          \ notebook. Error: {e}'\n        ) from e\n\n    try:\n        __kfp_write_parameters_cell(nb,\
          \ kwargs)\n        print(\n            f'[KFP Notebook] Executing notebook\
          \ with {len(nb.get(\"cells\", []))} cells',\n            flush=True)\n\n\
          \        # Use our custom streaming client for real-time output (defined\
          \ in the\n        # generated ephemeral source)\n        client = KFPStreamingNotebookClient(\n\
          \            nb,\n            timeout=None,\n            allow_errors=False,\n\
          \            store_widget_state=False,\n            kernel_name='python3')\n\
          \        client.execute(cwd=__KFP_EMBEDDED_ASSET_DIR)\n\n        print('[KFP\
          \ Notebook] Execution complete', flush=True)\n\n    except Exception as\
          \ e:\n        raise RuntimeError(f'Notebook execution failed. Error: {e}')\
          \ from e\n\n\n# Bind helper into dsl namespace so user code can call dsl.run_notebook(...)\n\
          dsl.run_notebook = kfp_run_notebook\n\n\ndef nb_generate_data(\n    generated_dataset:\
          \ dsl.Output[dsl.Dataset],\n    num_rows: int = 5,\n    prefix: str = \"\
          item\",\n    seed: int = 42,\n):\n    import shutil\n    print(\"[nb_generate_data]\
          \ Starting component\")\n    print(\n        f\"[nb_generate_data] Params\
          \ -> num_rows={num_rows}, prefix={prefix}, seed={seed}\"\n    )\n    dsl.run_notebook(num_rows=num_rows,\
          \ prefix=prefix, seed=seed)\n\n    # Notebook writes to /tmp/kfp_nb_outputs/dataset\n\
          \    src_dir = \"/tmp/kfp_nb_outputs/dataset\"\n    print(\n        f\"\
          [nb_generate_data] Copying notebook output from {src_dir} to {generated_dataset.path}\"\
          \n    )\n    shutil.copytree(src_dir, generated_dataset.path, dirs_exist_ok=True)\n\
          \    print(\"[nb_generate_data] Finished component\")\n\n"
        image: python:3.11
    exec-nb-process-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - nb_process_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'datasets' 'nbclient'\
          \ 'nbformat' 'ipykernel'  &&  python3 -m pip install --quiet --no-warn-script-location\
          \ 'kfp==2.14.6' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"\
          3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\n__KFP_EMBEDDED_ARCHIVE_B64 = 'H4sIAH05DmkC/+1X3Y/iNhDnef8KK32BissmfCwnJFZ9adWHqjrpqt7DBkUmmbBeEju1HS0I8b938kEgIQtbVXcPd/49hGQ8Mx7P/MY29r19/8snuv0daAiy91XglHjr13HG49N7Lnedkev2yLb3DZApTSVO3/sxMZqRRLMEFu7sYTQdz5zxyHYn49n4413P4PtHKkUASvkh1dRm6Y6vvk7/P0wmxe/sYVr2+mhy7PnpeOr23KnrjCejmevm/T+dTMc94nzL/l9JRvmaxjFdP3dthKgWRd9f/fd3hFgBxLGy5uQJPwjZF89K7OtdCjhkBSIEa3gcgi0EmWaC+4HIuEYFnsVxPZyApjmjUL4/1FKR6TTTxUTLWqhEJgOoJy9kP5FPVFJ0AlIRxl8g0BCS1Y6EKrZlxn0uNKyE2Hi8DgnNGEf3BZMVaD+l+pksyDoWKxqr/sBeg+57HUqeNWj6SRj3Y+Drwp5x3W/7OCl41pA4g5Z98yuVuQvPeuKr+Xm3LclnZJ5mfE3q5bQjKW2jLuMiQ4p8eCSXK1rsL2WHITmFvdif3g8Xs7aymqRCaiJUp/hFCd4ciKRISDUzVq9UiwUN/XzED5naXJ0uytPRsah5Uy9/SMoUkL9pnMGvUgrZWV7CFJHwT8YkhDeWWplh1Zvx9i+9tvxELEayIkkXx6Xbpagf02QVUgLbeUEl2FYcavCHPJZEO1XlOqeKpvNxs8pDBd6v5hx0aZ2FlqseP9/B2U7e/YGZQWdSvCpfC03jxb6OBjlWyDeQ6qP4ON8tmmHPS0ipBFJtEyTEigVayF1TsRzGukhckWfd6yS930Spz1d+Zem1XAtlJ3QDaKH6J+sh1oQp7YvN4i+ZwY3gvkimgeCWJFmg7Jz1JBKS6Gcgr5KmKeC7IIHgKkugtZ2URhjt/pLCnnXKpIe7YITM0/06o4PhmyZ5ktsWdXE7zcIsSXa+CoSE3NC1nZba4aIV60A6uw8PAFxVa25yf7IakJ+J6zi2c2mNzgsHHY5zVEl78qwNQOoXqj5mOQCOq17itOW6i4Grtas8Hc8DJEP+Zr8Ixhts8Kzz6l6w9ZWhuUixg84d5maveRMDxwMS9/KFZ2U6+vAR7QlVJOpYXu7exlqkR09DEr1/3/8ixYmIOef25/Hc7rKSyBJUFuuKyEjZhLbbrBK+j7V1wW/TtUmWTv3z43V+dmp1KsOWJmkM6FGqsh8q10/OktQMrsn5SBwCMZ4afwoO1+lf5egdxDnP5hXinDv8f8SpioPEGeK5EWJPLEb/lUJVNAWFziO7RaG37zO/Mc7UMya5eZ+pTJfF7wGfxeWvcUcshqwYL+AZXYPPeCRqMQ5wvAvmd9B0p59F5TB3VFwtLb7CnTih+SV00hD4SB0hUTy6O5h/swYGBgYGBgYGBgYGBgYGBgYGBgYGBj8S/gWc/uO2ACgAAA=='\n\
          __KFP_NOTEBOOK_REL_PATH = 'process_data.ipynb'\n\nimport base64 as __kfp_b64\n\
          import gzip as __kfp_gzip\nimport io as __kfp_io\nimport os as __kfp_os\n\
          import sys as __kfp_sys\nimport tarfile as __kfp_tarfile\nimport tempfile\
          \ as __kfp_tempfile\nfrom nbclient import NotebookClient\n\n# Extract embedded\
          \ archive at import time to ensure sys.path and globals are set\nprint('[KFP]\
          \ Extracting embedded notebook archive...', flush=True)\n__kfp_tmpdir =\
          \ __kfp_tempfile.TemporaryDirectory()\n__KFP_EMBEDDED_ASSET_DIR = __kfp_tmpdir.name\n\
          try:\n    __kfp_bytes = __kfp_b64.b64decode(__KFP_EMBEDDED_ARCHIVE_B64.encode('ascii'))\n\
          \    with __kfp_tarfile.open(fileobj=__kfp_io.BytesIO(__kfp_bytes), mode='r:gz')\
          \ as __kfp_tar:\n        __kfp_tar.extractall(path=__KFP_EMBEDDED_ASSET_DIR)\n\
          \    print(f'[KFP] Notebook archive extracted to: {__KFP_EMBEDDED_ASSET_DIR}',\
          \ flush=True)\nexcept Exception as __kfp_e:\n    raise RuntimeError(f'Failed\
          \ to extract embedded notebook archive: {__kfp_e}')\n\n# Always prepend\
          \ the extracted directory to sys.path for import resolution\nif __KFP_EMBEDDED_ASSET_DIR\
          \ not in __kfp_sys.path:\n    __kfp_sys.path.insert(0, __KFP_EMBEDDED_ASSET_DIR)\n\
          \    print(f'[KFP] Added notebook archive directory to Python path', flush=True)\n\
          \n# Optional convenience for generic embedded file variable name\n__KFP_EMBEDDED_ASSET_FILE\
          \ = __kfp_os.path.join(__KFP_EMBEDDED_ASSET_DIR, __KFP_NOTEBOOK_REL_PATH)\n\
          \n\nclass KFPStreamingNotebookClient(NotebookClient):\n    # Streams outputs\
          \ in real-time by emitting outputs during message processing.\n    def process_message(self,\
          \ msg, cell, cell_index):\n        # Call the parent implementation to handle\
          \ the message normally\n        output = super().process_message(msg, cell,\
          \ cell_index)\n\n        # If an output was created, stream it immediately\n\
          \        if output is not None:\n            _kfp_stream_single_output(output,\
          \ cell_index)\n\n        return output\n\ndef __kfp_write_parameters_cell(nb,\
          \ params):\n    \"\"\"Inject parameters following Papermill semantics.\n\
          \n    - If a cell tagged with 'parameters' exists, insert an overriding\n\
          \      'injected-parameters' cell immediately after it.\n    - Otherwise,\
          \ insert the 'injected-parameters' cell at the top.\n    \"\"\"\n    import\
          \ json\n\n    import nbformat\n\n    if not params:\n        return\n\n\
          \    # Build the injected parameters cell\n    assignments = []\n    for\
          \ key, value in params.items():\n        serialized = json.dumps(value)\n\
          \        assignments.append(key + ' = json.loads(' + repr(serialized) +\
          \ ')')\n    source = 'import json\\n' + '\\n'.join(assignments) + '\\n'\n\
          \    cell = nbformat.v4.new_code_cell(source=source)\n    cell.metadata.setdefault('tags',\
          \ [])\n    if 'injected-parameters' not in cell.metadata['tags']:\n    \
          \    cell.metadata['tags'].append('injected-parameters')\n\n    # Locate\
          \ the first 'parameters' tagged cell\n    insert_idx = 0\n    for idx, existing\
          \ in enumerate(nb.get('cells', [])):\n        if existing.get('cell_type')\
          \ != 'code':\n            continue\n        tags = existing.get('metadata',\
          \ {}).get('tags', []) or []\n        if 'parameters' in tags:\n        \
          \    insert_idx = idx + 1\n            break\n\n    nb.cells.insert(insert_idx,\
          \ cell)\n\ndef _kfp_stream_single_output(output, cell_idx):\n    \"\"\"\
          Stream a single notebook output immediately during execution.\n\n    Prints\
          \ stdout/stderr and text/plain display outputs to the console\n    so users\
          \ see cell output as it happens (no need to wait until the\n    notebook\
          \ finishes).\n    \"\"\"\n    import sys\n    output_type = output.get('output_type')\n\
          \n    if output_type == 'stream':\n        text = output.get('text', '')\n\
          \        if text:\n            try:\n                print(f'[nb cell {cell_idx}\
          \ stream] ', end='', flush=False)\n            except Exception:\n     \
          \           pass\n            print(text, end='' if text.endswith('\\n')\
          \ else '\\n', flush=True)\n    elif output_type == 'error':\n        for\
          \ line in output.get('traceback', []):\n            print(line, file=sys.stderr,\
          \ flush=True)\n    else:\n        # Handle display_data and execute_result\n\
          \        data = output.get('data', {})\n        if 'text/plain' in data:\n\
          \            print(data['text/plain'], flush=True)\n        elif 'application/json'\
          \ in data:\n            try:\n                import json as __kfp_json\n\
          \                parsed = data['application/json']\n                # Some\
          \ kernels send JSON as string; try to parse if needed\n                if\
          \ isinstance(parsed, str):\n                    try:\n                 \
          \       parsed = __kfp_json.loads(parsed)\n                    except Exception:\n\
          \                        pass\n                print(\n                \
          \    __kfp_json.dumps(parsed, indent=2, ensure_ascii=False),\n         \
          \           flush=True)\n            except Exception:\n               \
          \ # Fallback to raw\n                print(str(data.get('application/json')),\
          \ flush=True)\n        elif 'text/markdown' in data:\n            # Print\
          \ markdown as-is; frontends may render, logs will show raw markdown\n  \
          \          print(data['text/markdown'], flush=True)\n\ndef kfp_run_notebook(**kwargs):\n\
          \    \"\"\"Execute the embedded notebook with injected parameters.\n\n \
          \   Parameters provided via kwargs are injected into the notebook\n    following\
          \ Papermill semantics (after a parameters cell if present,\n    otherwise\
          \ at top). Execution uses a Python kernel; nbclient and\n    ipykernel must\
          \ be available at runtime (installed via\n    packages_to_install for notebook\
          \ components).\n    \"\"\"\n    import os\n    import subprocess\n    import\
          \ sys\n\n    from nbclient import NotebookClient\n    import nbformat\n\n\
          \    # Ensure a usable 'python3' kernel is present; install kernelspec if\
          \ missing\n    print('[KFP Notebook] Checking for Python kernel...', flush=True)\n\
          \    try:\n        from jupyter_client.kernelspec import KernelSpecManager\
          \  # type: ignore\n        ksm = KernelSpecManager()\n        have_py3 =\
          \ 'python3' in ksm.find_kernel_specs()\n        if not have_py3:\n     \
          \       print(\n                '[KFP Notebook] Python3 kernel not found,\
          \ installing...',\n                flush=True)\n            try:\n     \
          \           subprocess.run([\n                    sys.executable, '-m',\
          \ 'ipykernel', 'install', '--user',\n                    '--name', 'python3',\
          \ '--display-name', 'Python 3'\n                ],\n                   \
          \            check=True,\n                               stdout=subprocess.DEVNULL,\n\
          \                               stderr=subprocess.DEVNULL)\n           \
          \     print(\n                    '[KFP Notebook] Python3 kernel installed\
          \ successfully',\n                    flush=True)\n            except subprocess.CalledProcessError\
          \ as e:\n                raise RuntimeError(\n                    \"Failed\
          \ to install 'python3' kernelspec for ipykernel. \"\n                  \
          \  \"Ensure ipykernel is available in the environment or include it via\
          \ packages_to_install. \"\n                    f\"Error: {e}\") from e\n\
          \        else:\n            print('[KFP Notebook] Python3 kernel found',\
          \ flush=True)\n    except ImportError as e:\n        raise RuntimeError(\n\
          \            \"jupyter_client is not available. Ensure it's installed in\
          \ the environment or include it via packages_to_install. \"\n          \
          \  f\"Error: {e}\") from e\n\n    nb_path = os.path.join(__KFP_EMBEDDED_ASSET_DIR,\
          \ __KFP_NOTEBOOK_REL_PATH)\n\n    try:\n        nb = nbformat.read(nb_path,\
          \ as_version=4)\n    except Exception as e:\n        raise RuntimeError(\n\
          \            f'Failed to read notebook {nb_path}. Ensure it is a valid Jupyter\
          \ notebook. Error: {e}'\n        ) from e\n\n    try:\n        __kfp_write_parameters_cell(nb,\
          \ kwargs)\n        print(\n            f'[KFP Notebook] Executing notebook\
          \ with {len(nb.get(\"cells\", []))} cells',\n            flush=True)\n\n\
          \        # Use our custom streaming client for real-time output (defined\
          \ in the\n        # generated ephemeral source)\n        client = KFPStreamingNotebookClient(\n\
          \            nb,\n            timeout=None,\n            allow_errors=False,\n\
          \            store_widget_state=False,\n            kernel_name='python3')\n\
          \        client.execute(cwd=__KFP_EMBEDDED_ASSET_DIR)\n\n        print('[KFP\
          \ Notebook] Execution complete', flush=True)\n\n    except Exception as\
          \ e:\n        raise RuntimeError(f'Notebook execution failed. Error: {e}')\
          \ from e\n\n\n# Bind helper into dsl namespace so user code can call dsl.run_notebook(...)\n\
          dsl.run_notebook = kfp_run_notebook\n\n\ndef nb_process_data(\n    input_dataset:\
          \ dsl.Input[dsl.Dataset],\n    output_metrics: dsl.Output[dsl.Metrics],\n\
          \    output_results: dsl.Output[dsl.Artifact],\n    min_length: int = 0,\n\
          ):\n    import shutil\n    print(\"[nb_process_data] Starting component\"\
          )\n    print(\n        f\"[nb_process_data] Params -> min_length={min_length};\
          \ reading dataset from {input_dataset.path}\"\n    )\n\n    dsl.run_notebook(\n\
          \        input_dataset_path=input_dataset.path,\n        min_length=min_length,\n\
          \    )\n\n    # Results and metrics are written by the notebook under /tmp/kfp_nb_outputs\n\
          \    results_path = \"/tmp/kfp_nb_outputs/results.json\"\n    metrics_path\
          \ = \"/tmp/kfp_nb_outputs/metrics.json\"\n\n    print(f\"[nb_process_data]\
          \ Reading metrics from {metrics_path}\")\n    import json\n    with open(metrics_path,\
          \ \"r\", encoding=\"utf-8\") as f:\n        metrics_dict = json.load(f)\n\
          \n    # Log metrics (avoid zero if your UI ignores zeros)\n    for key,\
          \ value in metrics_dict.items():\n        if isinstance(value, (int, float))\
          \ and value != 0:\n            output_metrics.log_metric(key, float(value))\n\
          \n    print(f\"[nb_process_data] Copying results to {output_results.path}\"\
          )\n    output_results.name = \"results.json\"\n    shutil.copy(results_path,\
          \ output_results.path)\n\n    print(\"[nb_process_data] Finished component\"\
          )\n\n"
        image: python:3.11
pipelineInfo:
  description: Use notebook components to generate and process a dataset.
  name: notebook-two-step-pipeline
root:
  dag:
    tasks:
      nb-generate-data:
        cachingOptions: {}
        componentRef:
          name: comp-nb-generate-data
        inputs:
          parameters:
            num_rows:
              componentInputParameter: num_rows
            prefix:
              componentInputParameter: prefix
            seed:
              componentInputParameter: seed
        taskInfo:
          name: nb-generate-data
      nb-process-data:
        cachingOptions: {}
        componentRef:
          name: comp-nb-process-data
        dependentTasks:
        - nb-generate-data
        inputs:
          artifacts:
            input_dataset:
              taskOutputArtifact:
                outputArtifactKey: generated_dataset
                producerTask: nb-generate-data
          parameters:
            min_length:
              componentInputParameter: min_length
        taskInfo:
          name: nb-process-data
  inputDefinitions:
    parameters:
      min_length:
        defaultValue: 0.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      num_rows:
        defaultValue: 5.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      prefix:
        defaultValue: item
        isOptional: true
        parameterType: STRING
      seed:
        defaultValue: 42.0
        isOptional: true
        parameterType: NUMBER_INTEGER
schemaVersion: 2.1.0
sdkVersion: kfp-2.14.6
