import kfp
from kfp import dsl
from kfp import components as kfp_components


# Load components from GitHub (raw) similar to the IBM example
generate_data = kfp_components.load_component_from_url(
    "https://raw.githubusercontent.com/briangallagher/test-pipelines/main/basic-pipeline/components/generate_data_component.yaml"
)

process_data = kfp_components.load_component_from_url(
    "https://raw.githubusercontent.com/briangallagher/test-pipelines/main/basic-pipeline/components/process_data_component.yaml"
)


@dsl.pipeline(
    name="Basic two-step pipeline (v2 - remote components)",
    description="Generate a small dataset with a remote component, then process it with another remote component.",
)
def basic_two_step_pipeline_v2(
    num_rows: int = 5,
    prefix: str = "item",
    min_length: int = 0,
):
    """Two-step pipeline using components referenced from Git (raw URLs).

    Args:
        num_rows (int): Rows generated by step 1.
        prefix (str): Text prefix for generated rows.
        min_length (int): Minimum length filter in step 2.
    """

    # Step 1: Generate dataset (remote component)
    gen_op = (
        generate_data(
            num_rows=num_rows,
            prefix=prefix,
        ).set_caching_options(enable_caching=False)
    )

    # Step 2: Process dataset (remote component)
    _ = (
        process_data(
            input_dataset=gen_op.outputs["generated_dataset"],
            min_length=min_length,
        )
        .after(gen_op)
        .set_caching_options(enable_caching=False)
    )


if __name__ == "__main__":
    kfp.compiler.Compiler().compile(
        pipeline_func=basic_two_step_pipeline_v2,
        package_path=__file__.replace(".py", ".yaml"),
    )


